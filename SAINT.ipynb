{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOr6xYYCcxqgF1Vin7QLe7J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chanyelee/Dacon-electricity-forecast/blob/main/SAINT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall numpy==1.26.4 scipy==1.11.4\n",
        "!pip install -q pytorch-widedeep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "rQJpipQsVHQ0",
        "outputId": "9cb6402d-f134-426f-e5da-ed05c935b942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "blis",
                  "catalogue",
                  "certifi",
                  "click",
                  "confection",
                  "cramjam",
                  "cv2",
                  "cymem",
                  "dateutil",
                  "einops",
                  "filelock",
                  "fsspec",
                  "gensim",
                  "huggingface_hub",
                  "idna",
                  "joblib",
                  "langcodes",
                  "lightning_utilities",
                  "markdown_it",
                  "markupsafe",
                  "mdurl",
                  "mpmath",
                  "murmurhash",
                  "numpy",
                  "nvidia",
                  "packaging",
                  "pandas",
                  "preshed",
                  "pyarrow",
                  "pydantic",
                  "pytorch_widedeep",
                  "pytz",
                  "regex",
                  "requests",
                  "rich",
                  "safetensors",
                  "scipy",
                  "sentencepiece",
                  "shellingham",
                  "six",
                  "sklearn",
                  "spacy",
                  "srsly",
                  "sympy",
                  "thinc",
                  "threadpoolctl",
                  "tokenizers",
                  "torch",
                  "torchgen",
                  "torchmetrics",
                  "torchvision",
                  "tqdm",
                  "transformers",
                  "triton",
                  "typer",
                  "typing_extensions",
                  "typing_inspection",
                  "urllib3",
                  "wasabi",
                  "weasel",
                  "wrapt"
                ]
              },
              "id": "c90347d742bb4e94953f63b333a28011"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "try:\n",
        "    path = '/content/drive/MyDrive/위아이티'\n",
        "    os.chdir(path)\n",
        "    print(f\"현재 작업 디렉터리: {os.getcwd()}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"오류: '{path}' 폴더를 찾을 수 없습니다. 경로를 확인해주세요.\")\n",
        "\n",
        "print(\"\\n현재 폴더 내 파일 목록:\")\n",
        "!ls"
      ],
      "metadata": {
        "id": "_Z0eCqavGtYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=ResourceWarning)"
      ],
      "metadata": {
        "id": "ODgjSBoFXZ7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import holidays\n",
        "import math\n",
        "import copy\n",
        "import joblib"
      ],
      "metadata": {
        "id": "lyig3STuWOX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from pytorch_widedeep.models import WideDeep, SAINT\n",
        "from pytorch_widedeep.preprocessing import TabPreprocessor\n",
        "from pytorch_widedeep.training import Trainer\n",
        "from pytorch_widedeep.initializers import XavierNormal\n",
        "from torch.optim import Adam, AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from pytorch_widedeep.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "Y5tqvMbHWP8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. GPU 장치 설정\n",
        "# torch.cuda.is_available()는 CUDA를 지원하는 GPU가 있는지 확인하는 함수입니다.\n",
        "# GPU가 있으면 'cuda'로, 없으면 'cpu'로 장치를 자동으로 설정합니다.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 2. 설정된 장치 확인\n",
        "print(f\"✅ Using device: {device}\")\n",
        "\n",
        "# 3. GPU 사용 시, 이름과 메모리 상태 출력 (선택 사항이지만 확인에 유용)\n",
        "if device.type == 'cuda':\n",
        "    print(f\"✅ GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory Allocated: {torch.cuda.memory_allocated(0)/1024**3:.1f} GB\")\n",
        "    print(f\"Memory Cached:    {torch.cuda.memory_reserved(0)/1024**3:.1f} GB\")"
      ],
      "metadata": {
        "id": "Kk5tr-W3WR9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb4dfae9-382e-4c2c-ff93-5d85329f88e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_group_1 = pd.read_csv('train_group_1.csv')\n",
        "train_group_2 = pd.read_csv('train_group_2.csv')\n",
        "train_group_3 = pd.read_csv('train_group_3.csv')\n",
        "\n",
        "valid_group_1 = pd.read_csv('valid_group_1.csv')\n",
        "valid_group_2 = pd.read_csv('valid_group_2.csv')\n",
        "valid_group_3 = pd.read_csv('valid_group_3.csv')\n",
        "\n",
        "test_group_1 = pd.read_csv('test_group_1.csv')\n",
        "test_group_2 = pd.read_csv('test_group_2.csv')\n",
        "test_group_3 = pd.read_csv('test_group_3.csv')"
      ],
      "metadata": {
        "id": "p25dJimJY_Fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_memory(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    데이터프레임의 int64, float64 타입을 각각 int32, float32로 변경하여 메모리를 최적화합니다.\n",
        "    \"\"\"\n",
        "\n",
        "    # 변경 전 메모리 사용량 확인\n",
        "    mem_before = df.memory_usage(deep=True).sum()\n",
        "    print(f\"--- 변경 전 메모리: {mem_before / 1e6:.2f} MB ---\")\n",
        "\n",
        "    # 변경할 타입을 담을 딕셔너리 생성\n",
        "    conversion_dict = {}\n",
        "    for col, dtype in df.dtypes.items():\n",
        "        if dtype == 'int64':\n",
        "            conversion_dict[col] = 'int32'\n",
        "        elif dtype == 'float64':\n",
        "            conversion_dict[col] = 'float32'\n",
        "\n",
        "    # astype을 이용해 한 번에 변경\n",
        "    if conversion_dict:\n",
        "        df = df.astype(conversion_dict)\n",
        "        mem_after = df.memory_usage(deep=True).sum()\n",
        "\n",
        "        print(f\"--- 변경 후 메모리: {mem_after / 1e6:.2f} MB ---\")\n",
        "\n",
        "        # 메모리 절감량 요약\n",
        "        reduction = ((mem_before - mem_after) / mem_before) * 100\n",
        "        print(f\"✅ 총 {reduction:.2f}%의 메모리를 절감했습니다.\")\n",
        "    else:\n",
        "        print(\"✅ 변경할 int64 또는 float64 타입의 컬럼이 없습니다.\")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "Ffsbv--8ZDsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_group_1 = optimize_memory(train_group_1)\n",
        "train_group_2 = optimize_memory(train_group_2)\n",
        "train_group_3 = optimize_memory(train_group_3)\n",
        "\n",
        "valid_group_1 = optimize_memory(valid_group_1)\n",
        "valid_group_2 = optimize_memory(valid_group_2)\n",
        "valid_group_3 = optimize_memory(valid_group_3)\n",
        "\n",
        "test_group_1 = optimize_memory(test_group_1)\n",
        "test_group_2 = optimize_memory(test_group_2)\n",
        "test_group_3 = optimize_memory(test_group_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7NqPoVOmZGJY",
        "outputId": "e1a8135a-3d6d-4045-d2f2-30810f961b0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 변경 전 메모리: 21.70 MB ---\n",
            "--- 변경 후 메모리: 13.69 MB ---\n",
            "✅ 총 36.91%의 메모리를 절감했습니다.\n",
            "--- 변경 전 메모리: 19.49 MB ---\n",
            "--- 변경 후 메모리: 12.22 MB ---\n",
            "✅ 총 37.29%의 메모리를 절감했습니다.\n",
            "--- 변경 전 메모리: 6.03 MB ---\n",
            "--- 변경 후 메모리: 3.74 MB ---\n",
            "✅ 총 37.98%의 메모리를 절감했습니다.\n",
            "--- 변경 전 메모리: 2.14 MB ---\n",
            "--- 변경 후 메모리: 1.35 MB ---\n",
            "✅ 총 36.91%의 메모리를 절감했습니다.\n",
            "--- 변경 전 메모리: 1.92 MB ---\n",
            "--- 변경 후 메모리: 1.21 MB ---\n",
            "✅ 총 37.28%의 메모리를 절감했습니다.\n",
            "--- 변경 전 메모리: 0.59 MB ---\n",
            "--- 변경 후 메모리: 0.37 MB ---\n",
            "✅ 총 37.97%의 메모리를 절감했습니다.\n",
            "--- 변경 전 메모리: 2.01 MB ---\n",
            "--- 변경 후 메모리: 1.29 MB ---\n",
            "✅ 총 36.09%의 메모리를 절감했습니다.\n",
            "--- 변경 전 메모리: 1.81 MB ---\n",
            "--- 변경 후 메모리: 1.15 MB ---\n",
            "✅ 총 36.51%의 메모리를 절감했습니다.\n",
            "--- 변경 전 메모리: 0.56 MB ---\n",
            "--- 변경 후 메모리: 0.35 MB ---\n",
            "✅ 총 37.28%의 메모리를 절감했습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_COL = '전력소비량(kWh)'\n",
        "TARGET_COL_LOG = '전력소비량(kWh)_log'\n",
        "\n",
        "CAT_COLS = ['건물번호', 'hour', '요일구분', '월', '요일', '건물유형', '강수여부']\n",
        "\n",
        "g1_cont_cols = [\n",
        "    '기온(°C)', '강수량(mm)', '풍속(m/s)', '습도(%)', '전력소비량(kWh)_log', '전력소비량(kWh)', 'hour_sin', 'hour_cos', 'Time_Index',\n",
        "    '연면적(m2)', '냉방면적(m2)', '일조(hr)', '일사(MJ/m2)', '체감온도', '온습도지수', '일주일_전_전력소비량',\n",
        "    '1시간_전_전력소비량', '하루_전_전력소비량',\n",
        "]\n",
        "\n",
        "g2_cont_cols = g1_cont_cols + ['태양광용량(kW)']\n",
        "g3_cont_cols = g2_cont_cols + ['ESS저장용량(kWh)', 'PCS용량(kW)']"
      ],
      "metadata": {
        "id": "dZzi6YGpWV0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pretrain_saint_model(\n",
        "    pretrain_dfs: list,\n",
        "    cat_cols: list,\n",
        "    cont_cols: list,\n",
        "    pretrain_epochs: int = 10\n",
        "):\n",
        "    \"\"\"\n",
        "    '가짜 Target' 방식을 사용하여 안정적으로 자기지도학습을 수행하는 함수\n",
        "    \"\"\"\n",
        "    print(\"===== 🚀 1. SAINT 자기지도학습 시작 =====\")\n",
        "\n",
        "    all_features_df = pd.concat(pretrain_dfs, ignore_index=True, sort=False)\n",
        "\n",
        "    preprocessor = TabPreprocessor(\n",
        "        cat_embed_cols=cat_cols,\n",
        "        continuous_cols=cont_cols,\n",
        "        scaler=\"minmax\",\n",
        "        impute_missing=True\n",
        "    )\n",
        "    preprocessor.fit(all_features_df)\n",
        "\n",
        "    model = WideDeep(deeptabular=SAINT(\n",
        "        column_idx=preprocessor.column_idx,\n",
        "        cat_embed_input=preprocessor.cat_embed_input,\n",
        "        continuous_cols=cont_cols\n",
        "    ))\n",
        "    initializers = XavierNormal()\n",
        "\n",
        "    pretrain_optimizer = AdamW(model.parameters(), lr=5e-4, eps=1e-7)\n",
        "    trainer_pretrain = Trainer(\n",
        "        model=model,\n",
        "        objective='regression',\n",
        "        optimizers=pretrain_optimizer,\n",
        "        initializers=initializers,\n",
        "        clip_grad_norm=1.0\n",
        "    )\n",
        "\n",
        "    X_pretrain = preprocessor.transform(all_features_df).astype('float32')\n",
        "\n",
        "    dummy_target = np.zeros((len(X_pretrain), 1))\n",
        "\n",
        "    trainer_pretrain.fit(\n",
        "        X_tab=X_pretrain,\n",
        "        target=dummy_target, # 가짜 타겟 전달\n",
        "        pretrain_method='masked',\n",
        "        val_split=0.1, # 가짜 타겟이 있으므로 val_split 사용\n",
        "        n_epochs=pretrain_epochs,\n",
        "        batch_size=512\n",
        "    )\n",
        "\n",
        "    print(\"✅ 자기지도학습 완료\")\n",
        "    return model, preprocessor"
      ],
      "metadata": {
        "id": "r5jWIH2Lm7cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def finetune_saint_model(\n",
        "    model,\n",
        "    preprocessor,\n",
        "    finetune_df: pd.DataFrame,\n",
        "    target_col: str,\n",
        "    finetune_epochs: int = 100\n",
        "):\n",
        "    \"\"\"\n",
        "    사전학습된 SAINT 모델을 특정 데이터셋으로 미세조정(Fine-tuning)합니다.\n",
        "    \"\"\"\n",
        "    print(f\"===== 🚀 2. {target_col}에 대한 미세조정 시작 =====\")\n",
        "\n",
        "    X_finetune = preprocessor.transform(finetune_df).astype('float32')\n",
        "    y_finetune = finetune_df[target_col].values.reshape(-1, 1)\n",
        "\n",
        "    y_scaler = StandardScaler()\n",
        "    y_scaled = y_scaler.fit_transform(y_finetune)\n",
        "\n",
        "    finetune_optimizer = AdamW(model.parameters(), lr=1e-4, eps=1e-7)\n",
        "    finetune_scheduler = ReduceLROnPlateau(finetune_optimizer, mode='min', factor=0.2, patience=5)\n",
        "    callbacks = [EarlyStopping(patience=15, monitor='val_loss')]\n",
        "\n",
        "    trainer_finetune = Trainer(\n",
        "        model=model,\n",
        "        objective='mae',\n",
        "        optimizers=finetune_optimizer,\n",
        "        lr_schedulers=finetune_scheduler,\n",
        "        callbacks=callbacks,\n",
        "        clip_grad_norm=1.0\n",
        "    )\n",
        "\n",
        "    trainer_finetune.fit(\n",
        "        X_tab=X_finetune,\n",
        "        target=y_scaled,\n",
        "        n_epochs=finetune_epochs,\n",
        "        batch_size=64,\n",
        "        val_split=0.2\n",
        "    )\n",
        "\n",
        "    print(\"✅ 미세조정 완료\")\n",
        "    return model, y_scaler"
      ],
      "metadata": {
        "id": "DrkBQZ3Um94T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_full_training_pipeline(\n",
        "    pretrain_dfs: list,\n",
        "    finetune_groups: dict,\n",
        "    target_col: str, # 로그 변환된 타겟 컬럼 이름 (예: '전력소비량(kWh)_log')\n",
        "    cat_cols: list,\n",
        "    common_cont_cols: list,\n",
        "    pretrain_epochs: int = 10,\n",
        "    finetune_epochs: int = 100\n",
        "):\n",
        "    \"\"\"\n",
        "    자가학습부터 그룹별 미세조정까지 전체 파이프라인을 실행합니다.\n",
        "    전처리기는 피처(feature)만으로 학습됩니다.\n",
        "    \"\"\"\n",
        "    # --- 타겟 컬럼 이름 정의 ---\n",
        "    # 로그 타겟 이름으로부터 원본 타겟 이름을 추정 (예: '_log' 제거)\n",
        "    original_target_col = target_col.replace('_log', '')\n",
        "\n",
        "    # 1. 사전학습용 데이터(DataFrame)에서 타겟 컬럼들 제거\n",
        "    pretrain_features_dfs = []\n",
        "    for df in pretrain_dfs:\n",
        "        features_only_df = df.drop(columns=[target_col, original_target_col], errors='ignore')\n",
        "        pretrain_features_dfs.append(features_only_df)\n",
        "\n",
        "    # 2. 사전학습용 컬럼 이름 리스트(list)에서 타겟 컬럼들 제거\n",
        "    cont_cols_for_pretrain = [\n",
        "        col for col in common_cont_cols\n",
        "        if col not in [target_col, original_target_col]\n",
        "    ]\n",
        "\n",
        "    # 3. 자가학습(Pre-training) 수행\n",
        "    # 이제 데이터와 컬럼 리스트 모두 타겟 정보가 없는 상태로 전달됩니다.\n",
        "    base_model, preprocessor = pretrain_saint_model(\n",
        "        pretrain_dfs=pretrain_features_dfs,          # 타겟이 제거된 데이터\n",
        "        cat_cols=cat_cols,\n",
        "        cont_cols=cont_cols_for_pretrain,      # 타겟이 제거된 컬럼 리스트\n",
        "        pretrain_epochs=pretrain_epochs\n",
        "    )\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # 4. 그룹별 미세조정(Fine-tuning) 수행 (이하 동일)\n",
        "    for group_name, group_data in finetune_groups.items():\n",
        "        print(f\"\\n--- {group_name} 그룹 미세조정 시작 ---\")\n",
        "\n",
        "        model_to_finetune = copy.deepcopy(base_model)\n",
        "\n",
        "        finetuned_model, y_scaler = finetune_saint_model(\n",
        "            model=model_to_finetune,\n",
        "            preprocessor=preprocessor,\n",
        "            finetune_df=group_data['df'],\n",
        "            target_col=target_col,\n",
        "            finetune_epochs=finetune_epochs\n",
        "        )\n",
        "\n",
        "        results[group_name] = {\n",
        "            \"model\": finetuned_model,\n",
        "            \"preprocessor\": preprocessor,\n",
        "            \"y_scaler\": y_scaler\n",
        "        }\n",
        "\n",
        "    print(\"\\n\\n===== 🚀 모든 그룹에 대한 학습 최종 완료 =====\")\n",
        "    return results"
      ],
      "metadata": {
        "id": "RVngJEEqm_VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrain_dfs = [train_group_1, train_group_2, train_group_3]\n",
        "\n",
        "finetune_groups_dict = {\n",
        "    \"group1\": {\"df\": train_group_1, \"cont_cols\": g1_cont_cols},\n",
        "    \"group2\": {\"df\": train_group_2, \"cont_cols\": g2_cont_cols},\n",
        "    \"group3\": {\"df\": train_group_3, \"cont_cols\": g3_cont_cols}\n",
        "}\n",
        "\n",
        "# # --- 함수 호출 ---\n",
        "# 이제 target_col에 올바른 문자열 값이 전달됩니다.\n",
        "training_results = run_full_training_pipeline(\n",
        "    pretrain_dfs=pretrain_dfs,\n",
        "    finetune_groups=finetune_groups_dict,\n",
        "    target_col=TARGET_COL_LOG,\n",
        "    cat_cols=CAT_COLS,\n",
        "    common_cont_cols=g1_cont_cols, # 자가학습 기준이 되는 공통 피처\n",
        "    pretrain_epochs=15,\n",
        "    finetune_epochs=100\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0j1sUzrnDLc",
        "outputId": "f15ef0fc-9d0d-4922-cd30-a79f179cd193",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== 🚀 1. SAINT 자기지도학습 시작 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 자기지도학습 완료\n",
            "\n",
            "--- group1 그룹 미세조정 시작 ---\n",
            "===== 🚀 2. 전력소비량(kWh)_log에 대한 미세조정 시작 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 미세조정 완료\n",
            "\n",
            "--- group2 그룹 미세조정 시작 ---\n",
            "===== 🚀 2. 전력소비량(kWh)_log에 대한 미세조정 시작 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 미세조정 완료\n",
            "\n",
            "\n",
            "===== 🚀 모든 그룹에 대한 학습 최종 완료 =====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장할 디렉토리 생성\n",
        "save_dir = 'trained_models_final'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "for group_name, results in training_results.items():\n",
        "    print(f\"--- [{group_name}] 객체 저장 시작 ---\")\n",
        "\n",
        "    # 1. 모델(Model) 저장\n",
        "    model_path = os.path.join(save_dir, f'model_{group_name}.pt')\n",
        "    torch.save(results['model'].state_dict(), model_path)\n",
        "    print(f\"  ✅ 모델 저장 완료: {model_path}\")\n",
        "\n",
        "    # 2. 전처리기(Preprocessor) 저장\n",
        "    # 해결: 'joblib.dump'를 사용하여 전처리기 객체를 직접 저장합니다.\n",
        "    preprocessor_path = os.path.join(save_dir, f'preprocessor_{group_name}.pkl')\n",
        "    joblib.dump(results['preprocessor'], preprocessor_path)\n",
        "    print(f\"  ✅ 전처리기 저장 완료: {preprocessor_path}\")\n",
        "\n",
        "    # 3. 스케일러(Scaler) 저장\n",
        "    scaler_path = os.path.join(save_dir, f'y_scaler_{group_name}.pkl')\n",
        "    joblib.dump(results['y_scaler'], scaler_path)\n",
        "    print(f\"  ✅ 스케일러 저장 완료: {scaler_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6E02Bu9G5FF",
        "outputId": "55daa6bd-2728-4e32-b04c-9cf991b8abbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- [group1] 객체 저장 시작 ---\n",
            "  ✅ 모델 저장 완료: trained_models_final/model_group1.pt\n",
            "  ✅ 전처리기 저장 완료: trained_models_final/preprocessor_group1.pkl\n",
            "  ✅ 스케일러 저장 완료: trained_models_final/y_scaler_group1.pkl\n",
            "--- [group2] 객체 저장 시작 ---\n",
            "  ✅ 모델 저장 완료: trained_models_final/model_group2.pt\n",
            "  ✅ 전처리기 저장 완료: trained_models_final/preprocessor_group2.pkl\n",
            "  ✅ 스케일러 저장 완료: trained_models_final/y_scaler_group2.pkl\n",
            "--- [group3] 객체 저장 시작 ---\n",
            "  ✅ 모델 저장 완료: trained_models_final/model_group3.pt\n",
            "  ✅ 전처리기 저장 완료: trained_models_final/preprocessor_group3.pkl\n",
            "  ✅ 스케일러 저장 완료: trained_models_final/y_scaler_group3.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import joblib\n",
        "import os\n",
        "from pytorch_widedeep.models import WideDeep, SAINT\n",
        "\n",
        "# ---------------------------------------------------------------------------------\n",
        "# ⚙️ 1. 모델 뼈대를 생성하는 최종 함수\n",
        "# ---------------------------------------------------------------------------------\n",
        "def get_model_for_group(group_name, preprocessor):\n",
        "    \"\"\"\n",
        "    '불러온 preprocessor' 객체와 '에러 메시지'를 근거로\n",
        "    모델 뼈대를 100% 동일하게 재구성합니다.\n",
        "    \"\"\"\n",
        "    saint_params = {\n",
        "        'n_blocks': 2,\n",
        "        'n_heads': 8,\n",
        "        'attn_dropout': 0.1,\n",
        "        'ff_dropout': 0.1,\n",
        "    }\n",
        "\n",
        "    deeptabular = SAINT(\n",
        "        column_idx=preprocessor.column_idx,\n",
        "        cat_embed_input=preprocessor.cat_embed_input,\n",
        "        continuous_cols=list(preprocessor.continuous_cols), # 리스트 형태로 변환\n",
        "        **saint_params\n",
        "    )\n",
        "\n",
        "    model = WideDeep(deeptabular=deeptabular)\n",
        "\n",
        "    return model\n",
        "\n",
        "# ---------------------------------------------------------------------------------\n",
        "# ⚙️ 2. 전체 불러오기 파이프라인\n",
        "# ---------------------------------------------------------------------------------\n",
        "\n",
        "# 저장된 파일들이 있는 디렉토리\n",
        "load_dir = 'trained_models_final'\n",
        "\n",
        "# 불러온 객체들을 저장할 딕셔너리\n",
        "loaded_training_results = {}\n",
        "\n",
        "# 불러올 그룹 이름 리스트\n",
        "group_names = ['group1', 'group2', 'group3']\n",
        "\n",
        "print(\"===== 🚀 저장된 객체 불러오기 시작 =====\")\n",
        "\n",
        "for group_name in group_names:\n",
        "    print(f\"\\n--- [{group_name}] 객체 불러오기 시작 ---\")\n",
        "\n",
        "    # 1. 이 부분이 실행되고 있는지 확인해주세요.\n",
        "    # 전처리기를 불러오는 코드 라인입니다.\n",
        "    preprocessor_path = os.path.join(load_dir, f'preprocessor_{group_name}.pkl')\n",
        "    preprocessor = joblib.load(preprocessor_path)\n",
        "\n",
        "    # 2. 이 print문이 있는지 확인해주세요.\n",
        "    # 불러오기 완료를 알려주는 출력 라인입니다.\n",
        "    print(f\"  ✅ 전처리기 불러오기 완료: {preprocessor_path}\")\n",
        "\n",
        "    # 모델 뼈대 생성\n",
        "    model = get_model_for_group(group_name, preprocessor)\n",
        "\n",
        "    # 모델 가중치 불러오기\n",
        "    model_path = os.path.join(load_dir, f'model_{group_name}.pt')\n",
        "    state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.eval()\n",
        "    print(f\"  ✅ 모델 불러오기 완료: {model_path}\")\n",
        "\n",
        "    # 스케일러 불러오기\n",
        "    scaler_path = os.path.join(load_dir, f'y_scaler_{group_name}.pkl')\n",
        "    y_scaler = joblib.load(scaler_path)\n",
        "    print(f\"  ✅ 스케일러 불러오기 완료: {scaler_path}\")\n",
        "\n",
        "    # 불러온 객체들을 딕셔너리에 저장\n",
        "    loaded_training_results[group_name] = {\n",
        "        'model': model,\n",
        "        'preprocessor': preprocessor,\n",
        "        'y_scaler': y_scaler\n",
        "    }\n",
        "\n",
        "print(\"\\n\\n===== ✅ 모든 객체 불러오기 완료 =====\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-0BoKucG7-7",
        "outputId": "f95d23d0-6a2d-4328-ae2e-cab9e498d760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== 🚀 저장된 객체 불러오기 시작 =====\n",
            "\n",
            "--- [group1] 객체 불러오기 시작 ---\n",
            "  ✅ 전처리기 불러오기 완료: trained_models_final/preprocessor_group1.pkl\n",
            "  ✅ 모델 불러오기 완료: trained_models_final/model_group1.pt\n",
            "  ✅ 스케일러 불러오기 완료: trained_models_final/y_scaler_group1.pkl\n",
            "\n",
            "--- [group2] 객체 불러오기 시작 ---\n",
            "  ✅ 전처리기 불러오기 완료: trained_models_final/preprocessor_group2.pkl\n",
            "  ✅ 모델 불러오기 완료: trained_models_final/model_group2.pt\n",
            "  ✅ 스케일러 불러오기 완료: trained_models_final/y_scaler_group2.pkl\n",
            "\n",
            "--- [group3] 객체 불러오기 시작 ---\n",
            "  ✅ 전처리기 불러오기 완료: trained_models_final/preprocessor_group3.pkl\n",
            "  ✅ 모델 불러오기 완료: trained_models_final/model_group3.pt\n",
            "  ✅ 스케일러 불러오기 완료: trained_models_final/y_scaler_group3.pkl\n",
            "\n",
            "\n",
            "===== ✅ 모든 객체 불러오기 완료 =====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. SMAPE 평가 함수 (이전에 정의한 함수)\n",
        "# ======================================================================================\n",
        "def smape(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    SMAPE (Symmetric Mean Absolute Percentage Error)를 계산하는 함수입니다.\n",
        "    \"\"\"\n",
        "    numerator = np.abs(y_pred - y_true)\n",
        "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
        "    ratio = np.where(denominator == 0, 0, numerator / denominator)\n",
        "    return np.mean(ratio) * 100\n",
        "\n",
        "# ======================================================================================\n",
        "# 2. 그룹별 예측 및 평가 실행\n",
        "# ======================================================================================\n",
        "\n",
        "# --- 테스트 데이터 준비 ---\n",
        "# group_1_test_final, group_2_test_final, group_3_test_final이 정의되어 있다고 가정합니다.\n",
        "test_groups = {\n",
        "    \"group1\": valid_group_1,\n",
        "    \"group2\": valid_group_2,\n",
        "    \"group3\": valid_group_3,\n",
        "}\n",
        "\n",
        "# --- 최종 결과를 저장할 딕셔너리 ---\n",
        "smape_scores = {}\n",
        "\n",
        "print(\"===== 🚀 그룹별 테스트 데이터 예측 및 평가 시작 =====\")\n",
        "\n",
        "# training_results 딕셔너리를 순회하며 각 그룹에 대한 예측을 수행합니다.\n",
        "for group_name, results in loaded_training_results.items():\n",
        "    print(f\"\\n--- [{group_name}] 예측 평가 시작 ---\")\n",
        "\n",
        "    # 1. 해당 그룹의 학습된 객체들 가져오기\n",
        "    model = results['model']\n",
        "    preprocessor = results['preprocessor']\n",
        "    y_scaler = results['y_scaler']\n",
        "\n",
        "    # 2. 해당 그룹의 테스트 데이터 가져오기\n",
        "    test_df = test_groups[group_name]\n",
        "\n",
        "    # 3. 데이터 준비\n",
        "    # X_test는 전처리를 위해 타겟 컬럼을 제외한 모든 컬럼을 포함할 수 있습니다.\n",
        "    X_test = test_df\n",
        "    # y_true는 로그 변환되기 전의 원본 '전력소비량(kWh)' 컬럼입니다.\n",
        "    y_true = test_df['전력소비량(kWh)'].values\n",
        "\n",
        "    # 4. 피처 전처리\n",
        "    X_test_transformed = preprocessor.transform(X_test).astype('float32')\n",
        "\n",
        "    # 5. 예측 수행 (메모리 효율적인 배치 처리)\n",
        "    predictor = Trainer(model=model, objective='regression')\n",
        "    batch_size = 1024\n",
        "    n_batches = math.ceil(len(X_test_transformed) / batch_size)\n",
        "\n",
        "    predictions_log_list = [] # 로그 스케일의 예측 결과를 저장할 리스트\n",
        "\n",
        "    for i in range(n_batches):\n",
        "        start = i * batch_size\n",
        "        end = (i + 1) * batch_size\n",
        "        X_batch = X_test_transformed[start:end]\n",
        "\n",
        "        # 5-1. 모델 예측 (결과는 scaled log 값)\n",
        "        y_pred_scaled_batch = predictor.predict(X_tab=X_batch, batch_size=batch_size)\n",
        "\n",
        "        # 5-2. StandardScaler 역변환 (결과는 log 값)\n",
        "        y_pred_log_batch = y_scaler.inverse_transform(y_pred_scaled_batch.reshape(-1, 1))\n",
        "\n",
        "        predictions_log_list.append(y_pred_log_batch)\n",
        "\n",
        "    # 6. 전체 예측 결과 취합 및 최종 역변환\n",
        "    # 6-1. 모든 배치의 예측 결과를 합칩니다 (결과는 아직 log 스케일).\n",
        "    y_pred_log = np.vstack(predictions_log_list)\n",
        "\n",
        "    # 6-2. 로그 역변환(expm1)을 통해 최종적으로 원래 스케일로 복원합니다.\n",
        "    y_pred_original = np.expm1(y_pred_log)\n",
        "\n",
        "    # 7. SMAPE 계산 및 저장\n",
        "    score = smape(y_true, y_pred_original.flatten())\n",
        "    smape_scores[group_name] = score\n",
        "\n",
        "    print(f\"✅ [{group_name}] 예측 완료! SMAPE: {score:.4f} %\")\n",
        "\n",
        "print(\"\\n\\n===== ✅ 모든 그룹 평가 완료 =====\")\n",
        "for group_name, score in smape_scores.items():\n",
        "    print(f\"   - {group_name} SMAPE: {score:.4f} %\")"
      ],
      "metadata": {
        "id": "6OyiuVmVQo8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bc7c749-f22d-4078-b289-e44feb4b3215",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== 🚀 그룹별 테스트 데이터 예측 및 평가 시작 =====\n",
            "\n",
            "--- [group1] 예측 평가 시작 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ [group3] 예측 완료! SMAPE: 10.7259 %\n",
            "\n",
            "\n",
            "===== ✅ 모든 그룹 평가 완료 =====\n",
            "   - group1 SMAPE: 13.5345 %\n",
            "   - group2 SMAPE: 9.9692 %\n",
            "   - group3 SMAPE: 10.7259 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_for_single_group(group_name, loaded_training_results, validation_groups, test_groups):\n",
        "    \"\"\"\n",
        "    지정된 단일 그룹에 대한 재귀 예측을 수행합니다.\n",
        "    (시차 피처 생성 로직 수정 완료)\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- [{group_name}] 예측 시작 ---\")\n",
        "\n",
        "    # ------------------- 1. 객체 및 데이터 준비 -------------------\n",
        "    results = loaded_training_results[group_name]\n",
        "    model = results['model']\n",
        "    preprocessor = results['preprocessor']\n",
        "    y_scaler = results['y_scaler']\n",
        "\n",
        "    predictor = Trainer(model=model, objective='regression')\n",
        "    PREDICTION_HORIZON = len(test_groups[group_name])\n",
        "    print(f\"   - 예측 기간(스텝 수): {PREDICTION_HORIZON}\")\n",
        "\n",
        "    initial_window_df = validation_groups[group_name].tail(168).copy()\n",
        "    recursive_df = initial_window_df.copy()\n",
        "    future_rows_list = []\n",
        "\n",
        "    # ------------------- 2. 한 스텝씩 재귀 예측 수행 -------------------\n",
        "    for i in range(PREDICTION_HORIZON):\n",
        "        print(f\"   - {i+1}번째 스텝 예측 중...\")\n",
        "        # 2-1. 현재 스텝의 예측 입력(X) 준비\n",
        "        current_step_df = recursive_df.tail(1)\n",
        "        X_pred = preprocessor.transform(current_step_df).astype('float32')\n",
        "\n",
        "        # 2-2. 1개 스텝 예측\n",
        "        y_pred_scaled = predictor.predict(X_tab=X_pred, batch_size=32)\n",
        "\n",
        "        # 2-3. 예측값 역변환\n",
        "        y_pred_log = y_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
        "        y_pred_original = np.expm1(y_pred_log).flatten()[0]\n",
        "\n",
        "        # ✅ NaN 값 발생 시 예측 중단\n",
        "        if pd.isna(y_pred_original):\n",
        "            print(f\"스텝 {i+1}에서 NaN이 발생하여 [{group_name}] 그룹의 예측을 중단합니다! ❗️❗️❗️\")\n",
        "            break\n",
        "\n",
        "        # 2-4. 다음 스텝을 위한 피처 업데이트\n",
        "        next_step_info = test_groups[group_name].iloc[[i]].copy()\n",
        "        next_step_info['전력소비량(kWh)'] = y_pred_original\n",
        "        next_step_info['전력소비량(kWh)_log'] = y_pred_log.flatten()[0]\n",
        "\n",
        "        next_step_info['1시간_전_전력소비량'] = recursive_df['전력소비량(kWh)'].iloc[-1]\n",
        "        next_step_info['하루_전_전력소비량'] = recursive_df['전력소비량(kWh)'].iloc[-24]\n",
        "        next_step_info['일주일_전_전력소비량'] = recursive_df['전력소비량(kWh)'].iloc[-168]\n",
        "\n",
        "        future_rows_list.append(next_step_info)\n",
        "        recursive_df = pd.concat([recursive_df, next_step_info], ignore_index=True)\n",
        "\n",
        "    # ------------------- 3. 최종 결과 취합 -------------------\n",
        "    if not future_rows_list:\n",
        "        print(f\"   - [{group_name}] 그룹에 대한 예측값이 없습니다.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    predictions_df = pd.concat(future_rows_list, ignore_index=True)\n",
        "\n",
        "    temp_answer_df = pd.DataFrame({\n",
        "        'num_date_time': predictions_df['num_date_time'],\n",
        "        '전력소비량(kWh)': predictions_df['전력소비량(kWh)']\n",
        "    })\n",
        "\n",
        "    print(f\"✅ [{group_name}] 예측 완료! {len(temp_answer_df)}개의 예측값 생성.\")\n",
        "    return temp_answer_df"
      ],
      "metadata": {
        "id": "oFE2DjtYXJzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_groups = {\n",
        "    \"group1\": valid_group_1,\n",
        "    \"group2\": valid_group_2,\n",
        "    \"group3\": valid_group_3,\n",
        "}\n",
        "test_groups = {\n",
        "    \"group1\": test_group_1,\n",
        "    \"group2\": test_group_2,\n",
        "    \"group3\": test_group_3,\n",
        "}\n",
        "\n",
        "all_predictions_list = []\n",
        "\n",
        "# --- 'group1'에 대해서만 예측 실행 ---\n",
        "print(\"\\n===== 🚀 단일 그룹('group1') 예측 테스트 시작 =====\")\n",
        "group_1_predictions = predict_for_single_group(\n",
        "    group_name='group1',\n",
        "    loaded_training_results=loaded_training_results,\n",
        "    validation_groups=validation_groups,\n",
        "    test_groups=test_groups\n",
        ")\n",
        "# all_predictions_list.append(group1_predictions)"
      ],
      "metadata": {
        "id": "2_d2M3BsGydz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n===== 🚀 단일 그룹('group2') 예측 테스트 시작 =====\")\n",
        "group_2_predictions = predict_for_single_group(\n",
        "    group_name='group2',\n",
        "    loaded_training_results=loaded_training_results,\n",
        "    validation_groups=validation_groups,\n",
        "    test_groups=test_groups\n",
        ")"
      ],
      "metadata": {
        "id": "gy4wV1Sw9S68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n===== 🚀 단일 그룹('group3') 예측 테스트 시작 =====\")\n",
        "group_3_predictions = predict_for_single_group(\n",
        "    group_name='group3',\n",
        "    loaded_training_results=loaded_training_results,\n",
        "    validation_groups=validation_groups,\n",
        "    test_groups=test_groups\n",
        ")"
      ],
      "metadata": {
        "id": "E8wdlggo9ZvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_1_predictions.to_csv('group_1_prediction.csv', index = False)"
      ],
      "metadata": {
        "id": "u0JnZlC_9c-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_2_predictions.to_csv('group_2_prediction.csv', index = False)"
      ],
      "metadata": {
        "id": "syg3_PVK9fHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_3_predictions.to_csv('group_3_prediction.csv', index = False)"
      ],
      "metadata": {
        "id": "24KA_ZrLlDBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_1_answer = pd.read_csv('group_1_prediction.csv')\n",
        "group_2_answer = pd.read_csv('group_2_prediction.csv')\n",
        "group_3_answer = pd.read_csv('group_3_prediction.csv')"
      ],
      "metadata": {
        "id": "YaNGUVrFQQlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = pd.concat([group_1_answer, group_2_answer, group_3_answer], ignore_index=True)\n",
        "answer.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OLDiYDBbQwTa",
        "outputId": "3016901f-fd1c-40ed-fc44-c3755fb681f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   num_date_time  전력소비량(kWh)\n",
              "0  1_20240825 00   6495.1255\n",
              "1  1_20240825 01   2478.0930\n",
              "2  1_20240825 02   3330.1997\n",
              "3  1_20240825 03   1462.9817\n",
              "4  1_20240825 04   1651.8745"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f95bc2a0-2c60-4116-a2c9-a1a9065276d9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_date_time</th>\n",
              "      <th>전력소비량(kWh)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1_20240825 00</td>\n",
              "      <td>6495.1255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1_20240825 01</td>\n",
              "      <td>2478.0930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1_20240825 02</td>\n",
              "      <td>3330.1997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1_20240825 03</td>\n",
              "      <td>1462.9817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1_20240825 04</td>\n",
              "      <td>1651.8745</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f95bc2a0-2c60-4116-a2c9-a1a9065276d9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f95bc2a0-2c60-4116-a2c9-a1a9065276d9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f95bc2a0-2c60-4116-a2c9-a1a9065276d9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0e0d90d4-83f7-4bf6-bc60-1dbc96beeba0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0e0d90d4-83f7-4bf6-bc60-1dbc96beeba0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0e0d90d4-83f7-4bf6-bc60-1dbc96beeba0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "answer",
              "summary": "{\n  \"name\": \"answer\",\n  \"rows\": 16800,\n  \"fields\": [\n    {\n      \"column\": \"num_date_time\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16800,\n        \"samples\": [\n          \"62_20240829 14\",\n          \"30_20240829 01\",\n          \"54_20240825 08\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc804\\ub825\\uc18c\\ube44\\ub7c9(kWh)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3176.9191301381725,\n        \"min\": 29.28691,\n        \"max\": 24220.352,\n        \"num_unique_values\": 16710,\n        \"samples\": [\n          7886.1494,\n          2578.007,\n          736.0947\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer.to_csv('final_answer.csv', index = False)"
      ],
      "metadata": {
        "id": "q7uNy4HVQ65w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
