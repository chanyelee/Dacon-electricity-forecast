{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOr6xYYCcxqgF1Vin7QLe7J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chanyelee/Dacon-electricity-forecast/blob/main/SAINT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall numpy==1.26.4 scipy==1.11.4\n",
        "!pip install -q pytorch-widedeep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "rQJpipQsVHQ0",
        "outputId": "9cb6402d-f134-426f-e5da-ed05c935b942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "blis",
                  "catalogue",
                  "certifi",
                  "click",
                  "confection",
                  "cramjam",
                  "cv2",
                  "cymem",
                  "dateutil",
                  "einops",
                  "filelock",
                  "fsspec",
                  "gensim",
                  "huggingface_hub",
                  "idna",
                  "joblib",
                  "langcodes",
                  "lightning_utilities",
                  "markdown_it",
                  "markupsafe",
                  "mdurl",
                  "mpmath",
                  "murmurhash",
                  "numpy",
                  "nvidia",
                  "packaging",
                  "pandas",
                  "preshed",
                  "pyarrow",
                  "pydantic",
                  "pytorch_widedeep",
                  "pytz",
                  "regex",
                  "requests",
                  "rich",
                  "safetensors",
                  "scipy",
                  "sentencepiece",
                  "shellingham",
                  "six",
                  "sklearn",
                  "spacy",
                  "srsly",
                  "sympy",
                  "thinc",
                  "threadpoolctl",
                  "tokenizers",
                  "torch",
                  "torchgen",
                  "torchmetrics",
                  "torchvision",
                  "tqdm",
                  "transformers",
                  "triton",
                  "typer",
                  "typing_extensions",
                  "typing_inspection",
                  "urllib3",
                  "wasabi",
                  "weasel",
                  "wrapt"
                ]
              },
              "id": "c90347d742bb4e94953f63b333a28011"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "try:\n",
        "    path = '/content/drive/MyDrive/ìœ„ì•„ì´í‹°'\n",
        "    os.chdir(path)\n",
        "    print(f\"í˜„ì¬ ì‘ì—… ë””ë ‰í„°ë¦¬: {os.getcwd()}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ì˜¤ë¥˜: '{path}' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "print(\"\\ní˜„ì¬ í´ë” ë‚´ íŒŒì¼ ëª©ë¡:\")\n",
        "!ls"
      ],
      "metadata": {
        "id": "_Z0eCqavGtYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=ResourceWarning)"
      ],
      "metadata": {
        "id": "ODgjSBoFXZ7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import holidays\n",
        "import math\n",
        "import copy\n",
        "import joblib"
      ],
      "metadata": {
        "id": "lyig3STuWOX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from pytorch_widedeep.models import WideDeep, SAINT\n",
        "from pytorch_widedeep.preprocessing import TabPreprocessor\n",
        "from pytorch_widedeep.training import Trainer\n",
        "from pytorch_widedeep.initializers import XavierNormal\n",
        "from torch.optim import Adam, AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from pytorch_widedeep.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "Y5tqvMbHWP8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. GPU ì¥ì¹˜ ì„¤ì •\n",
        "# torch.cuda.is_available()ëŠ” CUDAë¥¼ ì§€ì›í•˜ëŠ” GPUê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
        "# GPUê°€ ìˆìœ¼ë©´ 'cuda'ë¡œ, ì—†ìœ¼ë©´ 'cpu'ë¡œ ì¥ì¹˜ë¥¼ ìë™ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 2. ì„¤ì •ëœ ì¥ì¹˜ í™•ì¸\n",
        "print(f\"âœ… Using device: {device}\")\n",
        "\n",
        "# 3. GPU ì‚¬ìš© ì‹œ, ì´ë¦„ê³¼ ë©”ëª¨ë¦¬ ìƒíƒœ ì¶œë ¥ (ì„ íƒ ì‚¬í•­ì´ì§€ë§Œ í™•ì¸ì— ìœ ìš©)\n",
        "if device.type == 'cuda':\n",
        "    print(f\"âœ… GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory Allocated: {torch.cuda.memory_allocated(0)/1024**3:.1f} GB\")\n",
        "    print(f\"Memory Cached:    {torch.cuda.memory_reserved(0)/1024**3:.1f} GB\")"
      ],
      "metadata": {
        "id": "Kk5tr-W3WR9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb4dfae9-382e-4c2c-ff93-5d85329f88e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_group_1 = pd.read_csv('train_group_1.csv')\n",
        "train_group_2 = pd.read_csv('train_group_2.csv')\n",
        "train_group_3 = pd.read_csv('train_group_3.csv')\n",
        "\n",
        "valid_group_1 = pd.read_csv('valid_group_1.csv')\n",
        "valid_group_2 = pd.read_csv('valid_group_2.csv')\n",
        "valid_group_3 = pd.read_csv('valid_group_3.csv')\n",
        "\n",
        "test_group_1 = pd.read_csv('test_group_1.csv')\n",
        "test_group_2 = pd.read_csv('test_group_2.csv')\n",
        "test_group_3 = pd.read_csv('test_group_3.csv')"
      ],
      "metadata": {
        "id": "p25dJimJY_Fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_memory(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    ë°ì´í„°í”„ë ˆì„ì˜ int64, float64 íƒ€ì…ì„ ê°ê° int32, float32ë¡œ ë³€ê²½í•˜ì—¬ ë©”ëª¨ë¦¬ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "\n",
        "    # ë³€ê²½ ì „ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸\n",
        "    mem_before = df.memory_usage(deep=True).sum()\n",
        "    print(f\"--- ë³€ê²½ ì „ ë©”ëª¨ë¦¬: {mem_before / 1e6:.2f} MB ---\")\n",
        "\n",
        "    # ë³€ê²½í•  íƒ€ì…ì„ ë‹´ì„ ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
        "    conversion_dict = {}\n",
        "    for col, dtype in df.dtypes.items():\n",
        "        if dtype == 'int64':\n",
        "            conversion_dict[col] = 'int32'\n",
        "        elif dtype == 'float64':\n",
        "            conversion_dict[col] = 'float32'\n",
        "\n",
        "    # astypeì„ ì´ìš©í•´ í•œ ë²ˆì— ë³€ê²½\n",
        "    if conversion_dict:\n",
        "        df = df.astype(conversion_dict)\n",
        "        mem_after = df.memory_usage(deep=True).sum()\n",
        "\n",
        "        print(f\"--- ë³€ê²½ í›„ ë©”ëª¨ë¦¬: {mem_after / 1e6:.2f} MB ---\")\n",
        "\n",
        "        # ë©”ëª¨ë¦¬ ì ˆê°ëŸ‰ ìš”ì•½\n",
        "        reduction = ((mem_before - mem_after) / mem_before) * 100\n",
        "        print(f\"âœ… ì´ {reduction:.2f}%ì˜ ë©”ëª¨ë¦¬ë¥¼ ì ˆê°í–ˆìŠµë‹ˆë‹¤.\")\n",
        "    else:\n",
        "        print(\"âœ… ë³€ê²½í•  int64 ë˜ëŠ” float64 íƒ€ì…ì˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "Ffsbv--8ZDsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_group_1 = optimize_memory(train_group_1)\n",
        "train_group_2 = optimize_memory(train_group_2)\n",
        "train_group_3 = optimize_memory(train_group_3)\n",
        "\n",
        "valid_group_1 = optimize_memory(valid_group_1)\n",
        "valid_group_2 = optimize_memory(valid_group_2)\n",
        "valid_group_3 = optimize_memory(valid_group_3)\n",
        "\n",
        "test_group_1 = optimize_memory(test_group_1)\n",
        "test_group_2 = optimize_memory(test_group_2)\n",
        "test_group_3 = optimize_memory(test_group_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7NqPoVOmZGJY",
        "outputId": "e1a8135a-3d6d-4045-d2f2-30810f961b0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ë³€ê²½ ì „ ë©”ëª¨ë¦¬: 21.70 MB ---\n",
            "--- ë³€ê²½ í›„ ë©”ëª¨ë¦¬: 13.69 MB ---\n",
            "âœ… ì´ 36.91%ì˜ ë©”ëª¨ë¦¬ë¥¼ ì ˆê°í–ˆìŠµë‹ˆë‹¤.\n",
            "--- ë³€ê²½ ì „ ë©”ëª¨ë¦¬: 19.49 MB ---\n",
            "--- ë³€ê²½ í›„ ë©”ëª¨ë¦¬: 12.22 MB ---\n",
            "âœ… ì´ 37.29%ì˜ ë©”ëª¨ë¦¬ë¥¼ ì ˆê°í–ˆìŠµë‹ˆë‹¤.\n",
            "--- ë³€ê²½ ì „ ë©”ëª¨ë¦¬: 6.03 MB ---\n",
            "--- ë³€ê²½ í›„ ë©”ëª¨ë¦¬: 3.74 MB ---\n",
            "âœ… ì´ 37.98%ì˜ ë©”ëª¨ë¦¬ë¥¼ ì ˆê°í–ˆìŠµë‹ˆë‹¤.\n",
            "--- ë³€ê²½ ì „ ë©”ëª¨ë¦¬: 2.14 MB ---\n",
            "--- ë³€ê²½ í›„ ë©”ëª¨ë¦¬: 1.35 MB ---\n",
            "âœ… ì´ 36.91%ì˜ ë©”ëª¨ë¦¬ë¥¼ ì ˆê°í–ˆìŠµë‹ˆë‹¤.\n",
            "--- ë³€ê²½ ì „ ë©”ëª¨ë¦¬: 1.92 MB ---\n",
            "--- ë³€ê²½ í›„ ë©”ëª¨ë¦¬: 1.21 MB ---\n",
            "âœ… ì´ 37.28%ì˜ ë©”ëª¨ë¦¬ë¥¼ ì ˆê°í–ˆìŠµë‹ˆë‹¤.\n",
            "--- ë³€ê²½ ì „ ë©”ëª¨ë¦¬: 0.59 MB ---\n",
            "--- ë³€ê²½ í›„ ë©”ëª¨ë¦¬: 0.37 MB ---\n",
            "âœ… ì´ 37.97%ì˜ ë©”ëª¨ë¦¬ë¥¼ ì ˆê°í–ˆìŠµë‹ˆë‹¤.\n",
            "--- ë³€ê²½ ì „ ë©”ëª¨ë¦¬: 2.01 MB ---\n",
            "--- ë³€ê²½ í›„ ë©”ëª¨ë¦¬: 1.29 MB ---\n",
            "âœ… ì´ 36.09%ì˜ ë©”ëª¨ë¦¬ë¥¼ ì ˆê°í–ˆìŠµë‹ˆë‹¤.\n",
            "--- ë³€ê²½ ì „ ë©”ëª¨ë¦¬: 1.81 MB ---\n",
            "--- ë³€ê²½ í›„ ë©”ëª¨ë¦¬: 1.15 MB ---\n",
            "âœ… ì´ 36.51%ì˜ ë©”ëª¨ë¦¬ë¥¼ ì ˆê°í–ˆìŠµë‹ˆë‹¤.\n",
            "--- ë³€ê²½ ì „ ë©”ëª¨ë¦¬: 0.56 MB ---\n",
            "--- ë³€ê²½ í›„ ë©”ëª¨ë¦¬: 0.35 MB ---\n",
            "âœ… ì´ 37.28%ì˜ ë©”ëª¨ë¦¬ë¥¼ ì ˆê°í–ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_COL = 'ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'\n",
        "TARGET_COL_LOG = 'ì „ë ¥ì†Œë¹„ëŸ‰(kWh)_log'\n",
        "\n",
        "CAT_COLS = ['ê±´ë¬¼ë²ˆí˜¸', 'hour', 'ìš”ì¼êµ¬ë¶„', 'ì›”', 'ìš”ì¼', 'ê±´ë¬¼ìœ í˜•', 'ê°•ìˆ˜ì—¬ë¶€']\n",
        "\n",
        "g1_cont_cols = [\n",
        "    'ê¸°ì˜¨(Â°C)', 'ê°•ìˆ˜ëŸ‰(mm)', 'í’ì†(m/s)', 'ìŠµë„(%)', 'ì „ë ¥ì†Œë¹„ëŸ‰(kWh)_log', 'ì „ë ¥ì†Œë¹„ëŸ‰(kWh)', 'hour_sin', 'hour_cos', 'Time_Index',\n",
        "    'ì—°ë©´ì (m2)', 'ëƒ‰ë°©ë©´ì (m2)', 'ì¼ì¡°(hr)', 'ì¼ì‚¬(MJ/m2)', 'ì²´ê°ì˜¨ë„', 'ì˜¨ìŠµë„ì§€ìˆ˜', 'ì¼ì£¼ì¼_ì „_ì „ë ¥ì†Œë¹„ëŸ‰',\n",
        "    '1ì‹œê°„_ì „_ì „ë ¥ì†Œë¹„ëŸ‰', 'í•˜ë£¨_ì „_ì „ë ¥ì†Œë¹„ëŸ‰',\n",
        "]\n",
        "\n",
        "g2_cont_cols = g1_cont_cols + ['íƒœì–‘ê´‘ìš©ëŸ‰(kW)']\n",
        "g3_cont_cols = g2_cont_cols + ['ESSì €ì¥ìš©ëŸ‰(kWh)', 'PCSìš©ëŸ‰(kW)']"
      ],
      "metadata": {
        "id": "dZzi6YGpWV0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pretrain_saint_model(\n",
        "    pretrain_dfs: list,\n",
        "    cat_cols: list,\n",
        "    cont_cols: list,\n",
        "    pretrain_epochs: int = 10\n",
        "):\n",
        "    \"\"\"\n",
        "    'ê°€ì§œ Target' ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì•ˆì •ì ìœ¼ë¡œ ìê¸°ì§€ë„í•™ìŠµì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜\n",
        "    \"\"\"\n",
        "    print(\"===== ğŸš€ 1. SAINT ìê¸°ì§€ë„í•™ìŠµ ì‹œì‘ =====\")\n",
        "\n",
        "    all_features_df = pd.concat(pretrain_dfs, ignore_index=True, sort=False)\n",
        "\n",
        "    preprocessor = TabPreprocessor(\n",
        "        cat_embed_cols=cat_cols,\n",
        "        continuous_cols=cont_cols,\n",
        "        scaler=\"minmax\",\n",
        "        impute_missing=True\n",
        "    )\n",
        "    preprocessor.fit(all_features_df)\n",
        "\n",
        "    model = WideDeep(deeptabular=SAINT(\n",
        "        column_idx=preprocessor.column_idx,\n",
        "        cat_embed_input=preprocessor.cat_embed_input,\n",
        "        continuous_cols=cont_cols\n",
        "    ))\n",
        "    initializers = XavierNormal()\n",
        "\n",
        "    pretrain_optimizer = AdamW(model.parameters(), lr=5e-4, eps=1e-7)\n",
        "    trainer_pretrain = Trainer(\n",
        "        model=model,\n",
        "        objective='regression',\n",
        "        optimizers=pretrain_optimizer,\n",
        "        initializers=initializers,\n",
        "        clip_grad_norm=1.0\n",
        "    )\n",
        "\n",
        "    X_pretrain = preprocessor.transform(all_features_df).astype('float32')\n",
        "\n",
        "    dummy_target = np.zeros((len(X_pretrain), 1))\n",
        "\n",
        "    trainer_pretrain.fit(\n",
        "        X_tab=X_pretrain,\n",
        "        target=dummy_target, # ê°€ì§œ íƒ€ê²Ÿ ì „ë‹¬\n",
        "        pretrain_method='masked',\n",
        "        val_split=0.1, # ê°€ì§œ íƒ€ê²Ÿì´ ìˆìœ¼ë¯€ë¡œ val_split ì‚¬ìš©\n",
        "        n_epochs=pretrain_epochs,\n",
        "        batch_size=512\n",
        "    )\n",
        "\n",
        "    print(\"âœ… ìê¸°ì§€ë„í•™ìŠµ ì™„ë£Œ\")\n",
        "    return model, preprocessor"
      ],
      "metadata": {
        "id": "r5jWIH2Lm7cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def finetune_saint_model(\n",
        "    model,\n",
        "    preprocessor,\n",
        "    finetune_df: pd.DataFrame,\n",
        "    target_col: str,\n",
        "    finetune_epochs: int = 100\n",
        "):\n",
        "    \"\"\"\n",
        "    ì‚¬ì „í•™ìŠµëœ SAINT ëª¨ë¸ì„ íŠ¹ì • ë°ì´í„°ì…‹ìœ¼ë¡œ ë¯¸ì„¸ì¡°ì •(Fine-tuning)í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    print(f\"===== ğŸš€ 2. {target_col}ì— ëŒ€í•œ ë¯¸ì„¸ì¡°ì • ì‹œì‘ =====\")\n",
        "\n",
        "    X_finetune = preprocessor.transform(finetune_df).astype('float32')\n",
        "    y_finetune = finetune_df[target_col].values.reshape(-1, 1)\n",
        "\n",
        "    y_scaler = StandardScaler()\n",
        "    y_scaled = y_scaler.fit_transform(y_finetune)\n",
        "\n",
        "    finetune_optimizer = AdamW(model.parameters(), lr=1e-4, eps=1e-7)\n",
        "    finetune_scheduler = ReduceLROnPlateau(finetune_optimizer, mode='min', factor=0.2, patience=5)\n",
        "    callbacks = [EarlyStopping(patience=15, monitor='val_loss')]\n",
        "\n",
        "    trainer_finetune = Trainer(\n",
        "        model=model,\n",
        "        objective='mae',\n",
        "        optimizers=finetune_optimizer,\n",
        "        lr_schedulers=finetune_scheduler,\n",
        "        callbacks=callbacks,\n",
        "        clip_grad_norm=1.0\n",
        "    )\n",
        "\n",
        "    trainer_finetune.fit(\n",
        "        X_tab=X_finetune,\n",
        "        target=y_scaled,\n",
        "        n_epochs=finetune_epochs,\n",
        "        batch_size=64,\n",
        "        val_split=0.2\n",
        "    )\n",
        "\n",
        "    print(\"âœ… ë¯¸ì„¸ì¡°ì • ì™„ë£Œ\")\n",
        "    return model, y_scaler"
      ],
      "metadata": {
        "id": "DrkBQZ3Um94T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_full_training_pipeline(\n",
        "    pretrain_dfs: list,\n",
        "    finetune_groups: dict,\n",
        "    target_col: str, # ë¡œê·¸ ë³€í™˜ëœ íƒ€ê²Ÿ ì»¬ëŸ¼ ì´ë¦„ (ì˜ˆ: 'ì „ë ¥ì†Œë¹„ëŸ‰(kWh)_log')\n",
        "    cat_cols: list,\n",
        "    common_cont_cols: list,\n",
        "    pretrain_epochs: int = 10,\n",
        "    finetune_epochs: int = 100\n",
        "):\n",
        "    \"\"\"\n",
        "    ìê°€í•™ìŠµë¶€í„° ê·¸ë£¹ë³„ ë¯¸ì„¸ì¡°ì •ê¹Œì§€ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
        "    ì „ì²˜ë¦¬ê¸°ëŠ” í”¼ì²˜(feature)ë§Œìœ¼ë¡œ í•™ìŠµë©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    # --- íƒ€ê²Ÿ ì»¬ëŸ¼ ì´ë¦„ ì •ì˜ ---\n",
        "    # ë¡œê·¸ íƒ€ê²Ÿ ì´ë¦„ìœ¼ë¡œë¶€í„° ì›ë³¸ íƒ€ê²Ÿ ì´ë¦„ì„ ì¶”ì • (ì˜ˆ: '_log' ì œê±°)\n",
        "    original_target_col = target_col.replace('_log', '')\n",
        "\n",
        "    # 1. ì‚¬ì „í•™ìŠµìš© ë°ì´í„°(DataFrame)ì—ì„œ íƒ€ê²Ÿ ì»¬ëŸ¼ë“¤ ì œê±°\n",
        "    pretrain_features_dfs = []\n",
        "    for df in pretrain_dfs:\n",
        "        features_only_df = df.drop(columns=[target_col, original_target_col], errors='ignore')\n",
        "        pretrain_features_dfs.append(features_only_df)\n",
        "\n",
        "    # 2. ì‚¬ì „í•™ìŠµìš© ì»¬ëŸ¼ ì´ë¦„ ë¦¬ìŠ¤íŠ¸(list)ì—ì„œ íƒ€ê²Ÿ ì»¬ëŸ¼ë“¤ ì œê±°\n",
        "    cont_cols_for_pretrain = [\n",
        "        col for col in common_cont_cols\n",
        "        if col not in [target_col, original_target_col]\n",
        "    ]\n",
        "\n",
        "    # 3. ìê°€í•™ìŠµ(Pre-training) ìˆ˜í–‰\n",
        "    # ì´ì œ ë°ì´í„°ì™€ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ ëª¨ë‘ íƒ€ê²Ÿ ì •ë³´ê°€ ì—†ëŠ” ìƒíƒœë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.\n",
        "    base_model, preprocessor = pretrain_saint_model(\n",
        "        pretrain_dfs=pretrain_features_dfs,          # íƒ€ê²Ÿì´ ì œê±°ëœ ë°ì´í„°\n",
        "        cat_cols=cat_cols,\n",
        "        cont_cols=cont_cols_for_pretrain,      # íƒ€ê²Ÿì´ ì œê±°ëœ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸\n",
        "        pretrain_epochs=pretrain_epochs\n",
        "    )\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # 4. ê·¸ë£¹ë³„ ë¯¸ì„¸ì¡°ì •(Fine-tuning) ìˆ˜í–‰ (ì´í•˜ ë™ì¼)\n",
        "    for group_name, group_data in finetune_groups.items():\n",
        "        print(f\"\\n--- {group_name} ê·¸ë£¹ ë¯¸ì„¸ì¡°ì • ì‹œì‘ ---\")\n",
        "\n",
        "        model_to_finetune = copy.deepcopy(base_model)\n",
        "\n",
        "        finetuned_model, y_scaler = finetune_saint_model(\n",
        "            model=model_to_finetune,\n",
        "            preprocessor=preprocessor,\n",
        "            finetune_df=group_data['df'],\n",
        "            target_col=target_col,\n",
        "            finetune_epochs=finetune_epochs\n",
        "        )\n",
        "\n",
        "        results[group_name] = {\n",
        "            \"model\": finetuned_model,\n",
        "            \"preprocessor\": preprocessor,\n",
        "            \"y_scaler\": y_scaler\n",
        "        }\n",
        "\n",
        "    print(\"\\n\\n===== ğŸš€ ëª¨ë“  ê·¸ë£¹ì— ëŒ€í•œ í•™ìŠµ ìµœì¢… ì™„ë£Œ =====\")\n",
        "    return results"
      ],
      "metadata": {
        "id": "RVngJEEqm_VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrain_dfs = [train_group_1, train_group_2, train_group_3]\n",
        "\n",
        "finetune_groups_dict = {\n",
        "    \"group1\": {\"df\": train_group_1, \"cont_cols\": g1_cont_cols},\n",
        "    \"group2\": {\"df\": train_group_2, \"cont_cols\": g2_cont_cols},\n",
        "    \"group3\": {\"df\": train_group_3, \"cont_cols\": g3_cont_cols}\n",
        "}\n",
        "\n",
        "# # --- í•¨ìˆ˜ í˜¸ì¶œ ---\n",
        "# ì´ì œ target_colì— ì˜¬ë°”ë¥¸ ë¬¸ìì—´ ê°’ì´ ì „ë‹¬ë©ë‹ˆë‹¤.\n",
        "training_results = run_full_training_pipeline(\n",
        "    pretrain_dfs=pretrain_dfs,\n",
        "    finetune_groups=finetune_groups_dict,\n",
        "    target_col=TARGET_COL_LOG,\n",
        "    cat_cols=CAT_COLS,\n",
        "    common_cont_cols=g1_cont_cols, # ìê°€í•™ìŠµ ê¸°ì¤€ì´ ë˜ëŠ” ê³µí†µ í”¼ì²˜\n",
        "    pretrain_epochs=15,\n",
        "    finetune_epochs=100\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0j1sUzrnDLc",
        "outputId": "f15ef0fc-9d0d-4922-cd30-a79f179cd193",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== ğŸš€ 1. SAINT ìê¸°ì§€ë„í•™ìŠµ ì‹œì‘ =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ìê¸°ì§€ë„í•™ìŠµ ì™„ë£Œ\n",
            "\n",
            "--- group1 ê·¸ë£¹ ë¯¸ì„¸ì¡°ì • ì‹œì‘ ---\n",
            "===== ğŸš€ 2. ì „ë ¥ì†Œë¹„ëŸ‰(kWh)_logì— ëŒ€í•œ ë¯¸ì„¸ì¡°ì • ì‹œì‘ =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ë¯¸ì„¸ì¡°ì • ì™„ë£Œ\n",
            "\n",
            "--- group2 ê·¸ë£¹ ë¯¸ì„¸ì¡°ì • ì‹œì‘ ---\n",
            "===== ğŸš€ 2. ì „ë ¥ì†Œë¹„ëŸ‰(kWh)_logì— ëŒ€í•œ ë¯¸ì„¸ì¡°ì • ì‹œì‘ =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ë¯¸ì„¸ì¡°ì • ì™„ë£Œ\n",
            "\n",
            "\n",
            "===== ğŸš€ ëª¨ë“  ê·¸ë£¹ì— ëŒ€í•œ í•™ìŠµ ìµœì¢… ì™„ë£Œ =====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì €ì¥í•  ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "save_dir = 'trained_models_final'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "for group_name, results in training_results.items():\n",
        "    print(f\"--- [{group_name}] ê°ì²´ ì €ì¥ ì‹œì‘ ---\")\n",
        "\n",
        "    # 1. ëª¨ë¸(Model) ì €ì¥\n",
        "    model_path = os.path.join(save_dir, f'model_{group_name}.pt')\n",
        "    torch.save(results['model'].state_dict(), model_path)\n",
        "    print(f\"  âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}\")\n",
        "\n",
        "    # 2. ì „ì²˜ë¦¬ê¸°(Preprocessor) ì €ì¥\n",
        "    # í•´ê²°: 'joblib.dump'ë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì²˜ë¦¬ê¸° ê°ì²´ë¥¼ ì§ì ‘ ì €ì¥í•©ë‹ˆë‹¤.\n",
        "    preprocessor_path = os.path.join(save_dir, f'preprocessor_{group_name}.pkl')\n",
        "    joblib.dump(results['preprocessor'], preprocessor_path)\n",
        "    print(f\"  âœ… ì „ì²˜ë¦¬ê¸° ì €ì¥ ì™„ë£Œ: {preprocessor_path}\")\n",
        "\n",
        "    # 3. ìŠ¤ì¼€ì¼ëŸ¬(Scaler) ì €ì¥\n",
        "    scaler_path = os.path.join(save_dir, f'y_scaler_{group_name}.pkl')\n",
        "    joblib.dump(results['y_scaler'], scaler_path)\n",
        "    print(f\"  âœ… ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ ì™„ë£Œ: {scaler_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6E02Bu9G5FF",
        "outputId": "55daa6bd-2728-4e32-b04c-9cf991b8abbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- [group1] ê°ì²´ ì €ì¥ ì‹œì‘ ---\n",
            "  âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: trained_models_final/model_group1.pt\n",
            "  âœ… ì „ì²˜ë¦¬ê¸° ì €ì¥ ì™„ë£Œ: trained_models_final/preprocessor_group1.pkl\n",
            "  âœ… ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ ì™„ë£Œ: trained_models_final/y_scaler_group1.pkl\n",
            "--- [group2] ê°ì²´ ì €ì¥ ì‹œì‘ ---\n",
            "  âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: trained_models_final/model_group2.pt\n",
            "  âœ… ì „ì²˜ë¦¬ê¸° ì €ì¥ ì™„ë£Œ: trained_models_final/preprocessor_group2.pkl\n",
            "  âœ… ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ ì™„ë£Œ: trained_models_final/y_scaler_group2.pkl\n",
            "--- [group3] ê°ì²´ ì €ì¥ ì‹œì‘ ---\n",
            "  âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: trained_models_final/model_group3.pt\n",
            "  âœ… ì „ì²˜ë¦¬ê¸° ì €ì¥ ì™„ë£Œ: trained_models_final/preprocessor_group3.pkl\n",
            "  âœ… ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ ì™„ë£Œ: trained_models_final/y_scaler_group3.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import joblib\n",
        "import os\n",
        "from pytorch_widedeep.models import WideDeep, SAINT\n",
        "\n",
        "# ---------------------------------------------------------------------------------\n",
        "# âš™ï¸ 1. ëª¨ë¸ ë¼ˆëŒ€ë¥¼ ìƒì„±í•˜ëŠ” ìµœì¢… í•¨ìˆ˜\n",
        "# ---------------------------------------------------------------------------------\n",
        "def get_model_for_group(group_name, preprocessor):\n",
        "    \"\"\"\n",
        "    'ë¶ˆëŸ¬ì˜¨ preprocessor' ê°ì²´ì™€ 'ì—ëŸ¬ ë©”ì‹œì§€'ë¥¼ ê·¼ê±°ë¡œ\n",
        "    ëª¨ë¸ ë¼ˆëŒ€ë¥¼ 100% ë™ì¼í•˜ê²Œ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    saint_params = {\n",
        "        'n_blocks': 2,\n",
        "        'n_heads': 8,\n",
        "        'attn_dropout': 0.1,\n",
        "        'ff_dropout': 0.1,\n",
        "    }\n",
        "\n",
        "    deeptabular = SAINT(\n",
        "        column_idx=preprocessor.column_idx,\n",
        "        cat_embed_input=preprocessor.cat_embed_input,\n",
        "        continuous_cols=list(preprocessor.continuous_cols), # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜\n",
        "        **saint_params\n",
        "    )\n",
        "\n",
        "    model = WideDeep(deeptabular=deeptabular)\n",
        "\n",
        "    return model\n",
        "\n",
        "# ---------------------------------------------------------------------------------\n",
        "# âš™ï¸ 2. ì „ì²´ ë¶ˆëŸ¬ì˜¤ê¸° íŒŒì´í”„ë¼ì¸\n",
        "# ---------------------------------------------------------------------------------\n",
        "\n",
        "# ì €ì¥ëœ íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬\n",
        "load_dir = 'trained_models_final'\n",
        "\n",
        "# ë¶ˆëŸ¬ì˜¨ ê°ì²´ë“¤ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
        "loaded_training_results = {}\n",
        "\n",
        "# ë¶ˆëŸ¬ì˜¬ ê·¸ë£¹ ì´ë¦„ ë¦¬ìŠ¤íŠ¸\n",
        "group_names = ['group1', 'group2', 'group3']\n",
        "\n",
        "print(\"===== ğŸš€ ì €ì¥ëœ ê°ì²´ ë¶ˆëŸ¬ì˜¤ê¸° ì‹œì‘ =====\")\n",
        "\n",
        "for group_name in group_names:\n",
        "    print(f\"\\n--- [{group_name}] ê°ì²´ ë¶ˆëŸ¬ì˜¤ê¸° ì‹œì‘ ---\")\n",
        "\n",
        "    # 1. ì´ ë¶€ë¶„ì´ ì‹¤í–‰ë˜ê³  ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\n",
        "    # ì „ì²˜ë¦¬ê¸°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì½”ë“œ ë¼ì¸ì…ë‹ˆë‹¤.\n",
        "    preprocessor_path = os.path.join(load_dir, f'preprocessor_{group_name}.pkl')\n",
        "    preprocessor = joblib.load(preprocessor_path)\n",
        "\n",
        "    # 2. ì´ printë¬¸ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\n",
        "    # ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œë¥¼ ì•Œë ¤ì£¼ëŠ” ì¶œë ¥ ë¼ì¸ì…ë‹ˆë‹¤.\n",
        "    print(f\"  âœ… ì „ì²˜ë¦¬ê¸° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: {preprocessor_path}\")\n",
        "\n",
        "    # ëª¨ë¸ ë¼ˆëŒ€ ìƒì„±\n",
        "    model = get_model_for_group(group_name, preprocessor)\n",
        "\n",
        "    # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "    model_path = os.path.join(load_dir, f'model_{group_name}.pt')\n",
        "    state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.eval()\n",
        "    print(f\"  âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: {model_path}\")\n",
        "\n",
        "    # ìŠ¤ì¼€ì¼ëŸ¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "    scaler_path = os.path.join(load_dir, f'y_scaler_{group_name}.pkl')\n",
        "    y_scaler = joblib.load(scaler_path)\n",
        "    print(f\"  âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: {scaler_path}\")\n",
        "\n",
        "    # ë¶ˆëŸ¬ì˜¨ ê°ì²´ë“¤ì„ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥\n",
        "    loaded_training_results[group_name] = {\n",
        "        'model': model,\n",
        "        'preprocessor': preprocessor,\n",
        "        'y_scaler': y_scaler\n",
        "    }\n",
        "\n",
        "print(\"\\n\\n===== âœ… ëª¨ë“  ê°ì²´ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ =====\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-0BoKucG7-7",
        "outputId": "f95d23d0-6a2d-4328-ae2e-cab9e498d760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== ğŸš€ ì €ì¥ëœ ê°ì²´ ë¶ˆëŸ¬ì˜¤ê¸° ì‹œì‘ =====\n",
            "\n",
            "--- [group1] ê°ì²´ ë¶ˆëŸ¬ì˜¤ê¸° ì‹œì‘ ---\n",
            "  âœ… ì „ì²˜ë¦¬ê¸° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: trained_models_final/preprocessor_group1.pkl\n",
            "  âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: trained_models_final/model_group1.pt\n",
            "  âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: trained_models_final/y_scaler_group1.pkl\n",
            "\n",
            "--- [group2] ê°ì²´ ë¶ˆëŸ¬ì˜¤ê¸° ì‹œì‘ ---\n",
            "  âœ… ì „ì²˜ë¦¬ê¸° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: trained_models_final/preprocessor_group2.pkl\n",
            "  âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: trained_models_final/model_group2.pt\n",
            "  âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: trained_models_final/y_scaler_group2.pkl\n",
            "\n",
            "--- [group3] ê°ì²´ ë¶ˆëŸ¬ì˜¤ê¸° ì‹œì‘ ---\n",
            "  âœ… ì „ì²˜ë¦¬ê¸° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: trained_models_final/preprocessor_group3.pkl\n",
            "  âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: trained_models_final/model_group3.pt\n",
            "  âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: trained_models_final/y_scaler_group3.pkl\n",
            "\n",
            "\n",
            "===== âœ… ëª¨ë“  ê°ì²´ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ =====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. SMAPE í‰ê°€ í•¨ìˆ˜ (ì´ì „ì— ì •ì˜í•œ í•¨ìˆ˜)\n",
        "# ======================================================================================\n",
        "def smape(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    SMAPE (Symmetric Mean Absolute Percentage Error)ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    numerator = np.abs(y_pred - y_true)\n",
        "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
        "    ratio = np.where(denominator == 0, 0, numerator / denominator)\n",
        "    return np.mean(ratio) * 100\n",
        "\n",
        "# ======================================================================================\n",
        "# 2. ê·¸ë£¹ë³„ ì˜ˆì¸¡ ë° í‰ê°€ ì‹¤í–‰\n",
        "# ======================================================================================\n",
        "\n",
        "# --- í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ---\n",
        "# group_1_test_final, group_2_test_final, group_3_test_finalì´ ì •ì˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
        "test_groups = {\n",
        "    \"group1\": valid_group_1,\n",
        "    \"group2\": valid_group_2,\n",
        "    \"group3\": valid_group_3,\n",
        "}\n",
        "\n",
        "# --- ìµœì¢… ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ ---\n",
        "smape_scores = {}\n",
        "\n",
        "print(\"===== ğŸš€ ê·¸ë£¹ë³„ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° í‰ê°€ ì‹œì‘ =====\")\n",
        "\n",
        "# training_results ë”•ì…”ë„ˆë¦¬ë¥¼ ìˆœíšŒí•˜ë©° ê° ê·¸ë£¹ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "for group_name, results in loaded_training_results.items():\n",
        "    print(f\"\\n--- [{group_name}] ì˜ˆì¸¡ í‰ê°€ ì‹œì‘ ---\")\n",
        "\n",
        "    # 1. í•´ë‹¹ ê·¸ë£¹ì˜ í•™ìŠµëœ ê°ì²´ë“¤ ê°€ì ¸ì˜¤ê¸°\n",
        "    model = results['model']\n",
        "    preprocessor = results['preprocessor']\n",
        "    y_scaler = results['y_scaler']\n",
        "\n",
        "    # 2. í•´ë‹¹ ê·¸ë£¹ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°\n",
        "    test_df = test_groups[group_name]\n",
        "\n",
        "    # 3. ë°ì´í„° ì¤€ë¹„\n",
        "    # X_testëŠ” ì „ì²˜ë¦¬ë¥¼ ìœ„í•´ íƒ€ê²Ÿ ì»¬ëŸ¼ì„ ì œì™¸í•œ ëª¨ë“  ì»¬ëŸ¼ì„ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "    X_test = test_df\n",
        "    # y_trueëŠ” ë¡œê·¸ ë³€í™˜ë˜ê¸° ì „ì˜ ì›ë³¸ 'ì „ë ¥ì†Œë¹„ëŸ‰(kWh)' ì»¬ëŸ¼ì…ë‹ˆë‹¤.\n",
        "    y_true = test_df['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'].values\n",
        "\n",
        "    # 4. í”¼ì²˜ ì „ì²˜ë¦¬\n",
        "    X_test_transformed = preprocessor.transform(X_test).astype('float32')\n",
        "\n",
        "    # 5. ì˜ˆì¸¡ ìˆ˜í–‰ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°°ì¹˜ ì²˜ë¦¬)\n",
        "    predictor = Trainer(model=model, objective='regression')\n",
        "    batch_size = 1024\n",
        "    n_batches = math.ceil(len(X_test_transformed) / batch_size)\n",
        "\n",
        "    predictions_log_list = [] # ë¡œê·¸ ìŠ¤ì¼€ì¼ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "\n",
        "    for i in range(n_batches):\n",
        "        start = i * batch_size\n",
        "        end = (i + 1) * batch_size\n",
        "        X_batch = X_test_transformed[start:end]\n",
        "\n",
        "        # 5-1. ëª¨ë¸ ì˜ˆì¸¡ (ê²°ê³¼ëŠ” scaled log ê°’)\n",
        "        y_pred_scaled_batch = predictor.predict(X_tab=X_batch, batch_size=batch_size)\n",
        "\n",
        "        # 5-2. StandardScaler ì—­ë³€í™˜ (ê²°ê³¼ëŠ” log ê°’)\n",
        "        y_pred_log_batch = y_scaler.inverse_transform(y_pred_scaled_batch.reshape(-1, 1))\n",
        "\n",
        "        predictions_log_list.append(y_pred_log_batch)\n",
        "\n",
        "    # 6. ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ ì·¨í•© ë° ìµœì¢… ì—­ë³€í™˜\n",
        "    # 6-1. ëª¨ë“  ë°°ì¹˜ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í•©ì¹©ë‹ˆë‹¤ (ê²°ê³¼ëŠ” ì•„ì§ log ìŠ¤ì¼€ì¼).\n",
        "    y_pred_log = np.vstack(predictions_log_list)\n",
        "\n",
        "    # 6-2. ë¡œê·¸ ì—­ë³€í™˜(expm1)ì„ í†µí•´ ìµœì¢…ì ìœ¼ë¡œ ì›ë˜ ìŠ¤ì¼€ì¼ë¡œ ë³µì›í•©ë‹ˆë‹¤.\n",
        "    y_pred_original = np.expm1(y_pred_log)\n",
        "\n",
        "    # 7. SMAPE ê³„ì‚° ë° ì €ì¥\n",
        "    score = smape(y_true, y_pred_original.flatten())\n",
        "    smape_scores[group_name] = score\n",
        "\n",
        "    print(f\"âœ… [{group_name}] ì˜ˆì¸¡ ì™„ë£Œ! SMAPE: {score:.4f} %\")\n",
        "\n",
        "print(\"\\n\\n===== âœ… ëª¨ë“  ê·¸ë£¹ í‰ê°€ ì™„ë£Œ =====\")\n",
        "for group_name, score in smape_scores.items():\n",
        "    print(f\"   - {group_name} SMAPE: {score:.4f} %\")"
      ],
      "metadata": {
        "id": "6OyiuVmVQo8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bc7c749-f22d-4078-b289-e44feb4b3215",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== ğŸš€ ê·¸ë£¹ë³„ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° í‰ê°€ ì‹œì‘ =====\n",
            "\n",
            "--- [group1] ì˜ˆì¸¡ í‰ê°€ ì‹œì‘ ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… [group3] ì˜ˆì¸¡ ì™„ë£Œ! SMAPE: 10.7259 %\n",
            "\n",
            "\n",
            "===== âœ… ëª¨ë“  ê·¸ë£¹ í‰ê°€ ì™„ë£Œ =====\n",
            "   - group1 SMAPE: 13.5345 %\n",
            "   - group2 SMAPE: 9.9692 %\n",
            "   - group3 SMAPE: 10.7259 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_for_single_group(group_name, loaded_training_results, validation_groups, test_groups):\n",
        "    \"\"\"\n",
        "    ì§€ì •ëœ ë‹¨ì¼ ê·¸ë£¹ì— ëŒ€í•œ ì¬ê·€ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "    (ì‹œì°¨ í”¼ì²˜ ìƒì„± ë¡œì§ ìˆ˜ì • ì™„ë£Œ)\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- [{group_name}] ì˜ˆì¸¡ ì‹œì‘ ---\")\n",
        "\n",
        "    # ------------------- 1. ê°ì²´ ë° ë°ì´í„° ì¤€ë¹„ -------------------\n",
        "    results = loaded_training_results[group_name]\n",
        "    model = results['model']\n",
        "    preprocessor = results['preprocessor']\n",
        "    y_scaler = results['y_scaler']\n",
        "\n",
        "    predictor = Trainer(model=model, objective='regression')\n",
        "    PREDICTION_HORIZON = len(test_groups[group_name])\n",
        "    print(f\"   - ì˜ˆì¸¡ ê¸°ê°„(ìŠ¤í… ìˆ˜): {PREDICTION_HORIZON}\")\n",
        "\n",
        "    initial_window_df = validation_groups[group_name].tail(168).copy()\n",
        "    recursive_df = initial_window_df.copy()\n",
        "    future_rows_list = []\n",
        "\n",
        "    # ------------------- 2. í•œ ìŠ¤í…ì”© ì¬ê·€ ì˜ˆì¸¡ ìˆ˜í–‰ -------------------\n",
        "    for i in range(PREDICTION_HORIZON):\n",
        "        print(f\"   - {i+1}ë²ˆì§¸ ìŠ¤í… ì˜ˆì¸¡ ì¤‘...\")\n",
        "        # 2-1. í˜„ì¬ ìŠ¤í…ì˜ ì˜ˆì¸¡ ì…ë ¥(X) ì¤€ë¹„\n",
        "        current_step_df = recursive_df.tail(1)\n",
        "        X_pred = preprocessor.transform(current_step_df).astype('float32')\n",
        "\n",
        "        # 2-2. 1ê°œ ìŠ¤í… ì˜ˆì¸¡\n",
        "        y_pred_scaled = predictor.predict(X_tab=X_pred, batch_size=32)\n",
        "\n",
        "        # 2-3. ì˜ˆì¸¡ê°’ ì—­ë³€í™˜\n",
        "        y_pred_log = y_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
        "        y_pred_original = np.expm1(y_pred_log).flatten()[0]\n",
        "\n",
        "        # âœ… NaN ê°’ ë°œìƒ ì‹œ ì˜ˆì¸¡ ì¤‘ë‹¨\n",
        "        if pd.isna(y_pred_original):\n",
        "            print(f\"ìŠ¤í… {i+1}ì—ì„œ NaNì´ ë°œìƒí•˜ì—¬ [{group_name}] ê·¸ë£¹ì˜ ì˜ˆì¸¡ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤! â—ï¸â—ï¸â—ï¸\")\n",
        "            break\n",
        "\n",
        "        # 2-4. ë‹¤ìŒ ìŠ¤í…ì„ ìœ„í•œ í”¼ì²˜ ì—…ë°ì´íŠ¸\n",
        "        next_step_info = test_groups[group_name].iloc[[i]].copy()\n",
        "        next_step_info['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'] = y_pred_original\n",
        "        next_step_info['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)_log'] = y_pred_log.flatten()[0]\n",
        "\n",
        "        next_step_info['1ì‹œê°„_ì „_ì „ë ¥ì†Œë¹„ëŸ‰'] = recursive_df['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'].iloc[-1]\n",
        "        next_step_info['í•˜ë£¨_ì „_ì „ë ¥ì†Œë¹„ëŸ‰'] = recursive_df['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'].iloc[-24]\n",
        "        next_step_info['ì¼ì£¼ì¼_ì „_ì „ë ¥ì†Œë¹„ëŸ‰'] = recursive_df['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'].iloc[-168]\n",
        "\n",
        "        future_rows_list.append(next_step_info)\n",
        "        recursive_df = pd.concat([recursive_df, next_step_info], ignore_index=True)\n",
        "\n",
        "    # ------------------- 3. ìµœì¢… ê²°ê³¼ ì·¨í•© -------------------\n",
        "    if not future_rows_list:\n",
        "        print(f\"   - [{group_name}] ê·¸ë£¹ì— ëŒ€í•œ ì˜ˆì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    predictions_df = pd.concat(future_rows_list, ignore_index=True)\n",
        "\n",
        "    temp_answer_df = pd.DataFrame({\n",
        "        'num_date_time': predictions_df['num_date_time'],\n",
        "        'ì „ë ¥ì†Œë¹„ëŸ‰(kWh)': predictions_df['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)']\n",
        "    })\n",
        "\n",
        "    print(f\"âœ… [{group_name}] ì˜ˆì¸¡ ì™„ë£Œ! {len(temp_answer_df)}ê°œì˜ ì˜ˆì¸¡ê°’ ìƒì„±.\")\n",
        "    return temp_answer_df"
      ],
      "metadata": {
        "id": "oFE2DjtYXJzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_groups = {\n",
        "    \"group1\": valid_group_1,\n",
        "    \"group2\": valid_group_2,\n",
        "    \"group3\": valid_group_3,\n",
        "}\n",
        "test_groups = {\n",
        "    \"group1\": test_group_1,\n",
        "    \"group2\": test_group_2,\n",
        "    \"group3\": test_group_3,\n",
        "}\n",
        "\n",
        "all_predictions_list = []\n",
        "\n",
        "# --- 'group1'ì— ëŒ€í•´ì„œë§Œ ì˜ˆì¸¡ ì‹¤í–‰ ---\n",
        "print(\"\\n===== ğŸš€ ë‹¨ì¼ ê·¸ë£¹('group1') ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ì‹œì‘ =====\")\n",
        "group_1_predictions = predict_for_single_group(\n",
        "    group_name='group1',\n",
        "    loaded_training_results=loaded_training_results,\n",
        "    validation_groups=validation_groups,\n",
        "    test_groups=test_groups\n",
        ")\n",
        "# all_predictions_list.append(group1_predictions)"
      ],
      "metadata": {
        "id": "2_d2M3BsGydz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n===== ğŸš€ ë‹¨ì¼ ê·¸ë£¹('group2') ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ì‹œì‘ =====\")\n",
        "group_2_predictions = predict_for_single_group(\n",
        "    group_name='group2',\n",
        "    loaded_training_results=loaded_training_results,\n",
        "    validation_groups=validation_groups,\n",
        "    test_groups=test_groups\n",
        ")"
      ],
      "metadata": {
        "id": "gy4wV1Sw9S68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n===== ğŸš€ ë‹¨ì¼ ê·¸ë£¹('group3') ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ì‹œì‘ =====\")\n",
        "group_3_predictions = predict_for_single_group(\n",
        "    group_name='group3',\n",
        "    loaded_training_results=loaded_training_results,\n",
        "    validation_groups=validation_groups,\n",
        "    test_groups=test_groups\n",
        ")"
      ],
      "metadata": {
        "id": "E8wdlggo9ZvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_1_predictions.to_csv('group_1_prediction.csv', index = False)"
      ],
      "metadata": {
        "id": "u0JnZlC_9c-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_2_predictions.to_csv('group_2_prediction.csv', index = False)"
      ],
      "metadata": {
        "id": "syg3_PVK9fHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_3_predictions.to_csv('group_3_prediction.csv', index = False)"
      ],
      "metadata": {
        "id": "24KA_ZrLlDBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_1_answer = pd.read_csv('group_1_prediction.csv')\n",
        "group_2_answer = pd.read_csv('group_2_prediction.csv')\n",
        "group_3_answer = pd.read_csv('group_3_prediction.csv')"
      ],
      "metadata": {
        "id": "YaNGUVrFQQlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = pd.concat([group_1_answer, group_2_answer, group_3_answer], ignore_index=True)\n",
        "answer.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OLDiYDBbQwTa",
        "outputId": "3016901f-fd1c-40ed-fc44-c3755fb681f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   num_date_time  ì „ë ¥ì†Œë¹„ëŸ‰(kWh)\n",
              "0  1_20240825 00   6495.1255\n",
              "1  1_20240825 01   2478.0930\n",
              "2  1_20240825 02   3330.1997\n",
              "3  1_20240825 03   1462.9817\n",
              "4  1_20240825 04   1651.8745"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f95bc2a0-2c60-4116-a2c9-a1a9065276d9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_date_time</th>\n",
              "      <th>ì „ë ¥ì†Œë¹„ëŸ‰(kWh)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1_20240825 00</td>\n",
              "      <td>6495.1255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1_20240825 01</td>\n",
              "      <td>2478.0930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1_20240825 02</td>\n",
              "      <td>3330.1997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1_20240825 03</td>\n",
              "      <td>1462.9817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1_20240825 04</td>\n",
              "      <td>1651.8745</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f95bc2a0-2c60-4116-a2c9-a1a9065276d9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f95bc2a0-2c60-4116-a2c9-a1a9065276d9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f95bc2a0-2c60-4116-a2c9-a1a9065276d9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0e0d90d4-83f7-4bf6-bc60-1dbc96beeba0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0e0d90d4-83f7-4bf6-bc60-1dbc96beeba0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0e0d90d4-83f7-4bf6-bc60-1dbc96beeba0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "answer",
              "summary": "{\n  \"name\": \"answer\",\n  \"rows\": 16800,\n  \"fields\": [\n    {\n      \"column\": \"num_date_time\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16800,\n        \"samples\": [\n          \"62_20240829 14\",\n          \"30_20240829 01\",\n          \"54_20240825 08\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc804\\ub825\\uc18c\\ube44\\ub7c9(kWh)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3176.9191301381725,\n        \"min\": 29.28691,\n        \"max\": 24220.352,\n        \"num_unique_values\": 16710,\n        \"samples\": [\n          7886.1494,\n          2578.007,\n          736.0947\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer.to_csv('final_answer.csv', index = False)"
      ],
      "metadata": {
        "id": "q7uNy4HVQ65w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
